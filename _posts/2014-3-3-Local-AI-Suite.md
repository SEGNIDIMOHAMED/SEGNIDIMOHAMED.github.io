---
layout: post
title: The Imperative of Secure AI Systems
---

The rapid proliferation of AI services has led to a deluge of new providers and technologies. As companies and individuals leverage these services, they often find themselves dealing with a large pool of providers, microservices, and terms of use. This can pose significant risks to security and privacy.

**The Risks of AI Services**

As we integrate AI tools into our workflows, they can become vulnerable to activity spying, which can be easily exploited by attackers. The list of potential malicious uses of private data passed to cloud AI systems is alarming, including the theft of personal information, work behavior, responsibilities, intellectual property risks, and enhanced social engineering cyberattacks.

**Insufficient Security Measures**

While measures like anonymous sessions, encrypted data, no-data-save policies, and end-to-end encrypted communications are essential, they are not enough to protect us against malicious uses. Anonymous sessions can be compromised if the data contains personal information. Encrypted data can still be vulnerable if the system is compromised. No-data-save policies may decrease the value of AI systems for many tasks that require iterations.

**The Need for a Holistic Approach**

To achieve truly secure AI systems, we must go beyond mere encryption and anonymization. We need to develop AI systems that are designed with security in mind from the outset, capable of detecting and responding to potential threats in real-time. This requires collaboration between developers, policymakers, and end-users.

**The Case for Local AI Systems**

BE LOCAL (and open !), a mantra that is changing the way we approach AI development and deployment. By keeping AI systems local, we can significantly reduce the risk of data leakage and confidentiality breaches. No longer will sensitive information be transmitted over the internet, where it can be intercepted or accessed by unauthorized parties.

**The Hardware Problem**

Currently, an AI system requires a significant investment, with professional equipment costing around $5,000. However, as AI systems develop and computation becomes a standard for modern computers, it will become easier to run local AI systems at a lower cost. Prices are likely to drop by a factor of two every two years for the same amount of performance.

**The Challenges Ahead**

While the benefits of local AI systems are clear, their development requires financial support from transparent and independent organizations. The open-source community for local AI development needs resources to build great, secure local AI systems.

**Conclusion**

The development of secure AI systems is a pressing concern that requires immediate attention. By promoting local AI systems, we can create a more resilient and secure ecosystem that benefits individuals, organizations, and communities alike. It's time to rethink our approach to AI development and deployment, putting security and privacy at the forefront of our efforts.

**Sources:**

* [Recommandations de sécurité pour un système DIA génératif](https://cyber.gouv.fr/publications/recommandations-de-securite-pour-un-systeme-dia-generatif)
* [ChatGPT side-channel attack has easy fix, but it's still a problem](https://www.theregister.com/2024/03/18/chatgpt_sidechannel_attack_has_easy/)


![Cost/performance of LLM](https://www.reddit.com/r/LocalLLaMA/comments/1cakcfq/chatbot_arena_results_are_in_llama_3_dominates/#lightbox)