---
layout: post
title: "Certified Organic Content"
---

The practice of adding disclaimers to AI-generated content is one way to make sure that people know that it might be misleading, or totally wrong.  In other words, the creator knows that a model's effectiveness is expected to vary, so they encourage the human seeing it to be more skeptical than usual and maybe cut it some extra slack.  However, since both AI and misinformation are both so increasingly embedded in our digital experiences, it could make more sense in the future to call out when content is 100% 'organic' or reviewed by a human expert.

<!--more-->

One reason is purely a practical one, and the other is based on changing expectations.  The scope and penetration of machine-made decisions is already difficult to unweave from the fabric of any content on the internet.  And in the near future, the expectation that any given content is assisted or completely generated by a machine versus a human will be even more status quo.  Personally speaking, I've already run into plenty of situations where I found myself questioning, 'is this a bad writer, or just bad robo-content?'

When that time comes, I think a lot of people will be more interested in knowing that specific content is 'Certified Organic' and created by humans, versus being made aware of when its AI-generated.  Just like how more people care more today about the food or other stuff they put in their body than they did a hundred years ago, there's a growing awareness that the content we choose to 'ingest' affects our emotional health and even the wiring of our brains.  As time passes, a growing number of people will become more selective about whether they're consuming 'processed' digital content, versus something organically generated.

Of course, even if adding public disclaimers becomes less useful over time, there will always be a responsibility behind the scenes to catalog the jobs that AI is doing in a given system.  For example, it's critical to keep track of what decisions in a system are decided based on personal information.  It's also important to be aware of which decisions are probabilistic, regardless of whether there's anything personal involved.  For the former, there's privacy concerns and evolving laws and regulations to reckon with.  And for the latter, there's always some cost involved when machines get things wrong.  If we have a sense of what gets decided by a model, we can pay more attention to the riskiest decisions, in order to avoid the highest costs and cover up those mistakes in some elegant way.

Outside of the internal responsibilities of the system owners however, I still think that the people on the reflective side of the two-way mirror will ultimately care more about knowing what was created by other people, versus needing confirmation of what specifically came from machines.  (Explaining *why* a machine did what it did is another area that could see more attention soon, and that could become either way harder or easier to do, the more opaque and powerful these models become.  But that's a topic for another day.)

****

_Books I've read that probably influenced this post:_

* [Building Intelligent Systems](https://www.thriftbooks.com/w/building-intelligent-systems-a-guide-to-machine-learning-engineering_geoff-hulten/18647469/item/27103403/)
* [Team Human](https://www.thriftbooks.com/w/team-human_douglas-rushkoff/19749977/)
* [Power and Prediction](https://www.thriftbooks.com/w/power-and-prediction-the-disruptive-economics-of-artificial-intelligence/36331348/)

****

*A note about this post*

*Most of my writing these days is either just for me, or for my job.  When I do write with the intention of posting something in public, I either get stuck in perfectionist limbo, or find other excuses to stop myself from actually sharing anything online.*

*As someone who works with AI-driven systems, it's both an inspiring and sometimes frustrating time to be alive.  Not only are there now celebrity-level model architectures, but anyone is now able to interact with these models in the same way we would do a Google search or write an instruction manual.  These posts will cover both the highs and lows of what I think this all implies for people on both sides of the two-way mirror (my current favorite metaphor for the way these models exist in the world).*

*These were all intended to be longer posts. Maybe they still will be someday.  For now, I'd like to share them as topics that might inspire others to go down their own personal rabbit holes, or serve as jumping off points for conversations with other technology wranglers and daydreamers.*
