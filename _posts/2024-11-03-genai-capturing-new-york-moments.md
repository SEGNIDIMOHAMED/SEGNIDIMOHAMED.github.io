---
layout: post
title: "Learning about GenAI and creativity"
excerpt: "Exploring generative AI tools to capture moments in NYC - my first creative project using Runway, Udio, and Kling AI to experiment with this emerging technology."
---

Learning about GenAI and creativity
===

I moved to New York last month. An exciting empty page - soon filled with too many bullet points of things to do... One has stuck with me: how can I capture this very specific moment? I started messing with different generative AI tools, and in this post I wanted to share some of the process and pain points. I'm more tech than creative, but would love to hear any suggestions!

## The Idea
I stumbled on inspiration in our first week. My husband and I visited the Stonewall Inn, where Tree, [an activist](<https://punchdrink.com/articles/tree-sequoia-is-the-spirit-of-stonewall-inn-bar-nyc/)>), shared history and gossip. 

It brought back teenage memories of listening to *An Englishman in New York*. There’s something of a hero in characters like [Quentin Crisp](https://en.wikipedia.org/wiki/Quentin_Crisp). 

What if he'd been a Frenchman in Hoboken?

## Kick-off
It’s easier to edit than to create wholesale. I found that to be a theme in GenAI, and certainly in this project. 

I began planning with a stream of consciousness and ChatGPT. 
> "Help me plan a little creative project. My goal is to mess about and get hands-on with genAI…"

Talking through and writing down my thoughts this way helped a lot.

### Approach
- List the AI processes in scope
- Summarize the thematic elements
- Generate variations

## Music & Lyrics
I used [Udio](https://www.udio.com/home) for a 30s snippet.

Getting the spirit of the song right took a few tries. Some experiments were fun, but very far from what I intended; for example, this French-sounding song was lovely but not quite right:  
[Listen on Udio](https://www.udio.com/songs/7LKtzrHMMWx9c2c6UE2hbP)  
<iframe src="https://www.udio.com/embed/7LKtzrHMMWx9c2c6UE2hbP?embedVariant=default" style="width:700px; height:228px; border-radius:12px;"></iframe>

Once I got a song that seemed to match the structure and themes I wanted, I edited the lyrics with ChatGPT. That process helped me a lot.  
[Final Song on Udio](https://www.udio.com/songs/s2VLZbpyZyK7ZcMyUeNBBz)  
<iframe src="https://www.udio.com/embed/s2VLZbpyZyK7ZcMyUeNBBz?embedVariant=default" style="width:700px; height:228px; border-radius:12px;"></iframe>

## Generating Some Images
I had high hopes for Runway on the image generation side, though it took me a while to realize I was going down some dead-ends creatively.

A lot of terrible eyes and probably overloading the query with semantics.  
*Prompt example*:  
> “Medium-full shot of a cyclist singing while riding through an autumn street in New Jersey. The cyclist is dressed in casual, comfortable clothing, captured in a realistic, cinematic style. The person should appear detailed and expressive, with a focus on natural movements and facial expression while singing. The background is minimalist, with just a few fall leaves scattered and soft, natural light illuminating the scene. The Statue of Liberty is visible in the distance, but the emphasis is on the cyclist's realism, personality, and connection to the moment.”

![biker image]

After a long break, I tried Kling AI (klingai.com). Support for reference images and a [detailed guide](https://docs.qingque.cn/d/home/eZQCtOj9fX_6cUjT_0yuk-yrL) made a huge difference.

![hat image]

## Adding Lip-Sync & Generative Video
"Done is better than perfect," so even though I wasn’t 100% satisfied with any step in the process, I pushed through to the lip-sync stage. This was actually the step with the least creative effort—it feels like this will either work or it won’t. It really didn’t work the first time, probably because I started with a side-on image.

The final product is:

---

## Thanks
Thanks to everyone who’s been so welcoming to my husband and me in New York.
